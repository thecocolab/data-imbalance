{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a71df60",
   "metadata": {},
   "source": [
    "# Data imbalance analysis\n",
    "## Comparing the impact of dataset imbalance on classification performance metrics\n",
    "In this notebook, we are going to explore how data imbalance affect classification scores on four different tasks, which have been chosen to exemplify typical use cases of ML analysis in neuroscience. To keep it simple, we will focus on binary classification problems (0 vs 1).\n",
    "\n",
    "The four tasks are :\n",
    "1. Synthetic data\n",
    "2. EEG alpha oscillations (resting-state Eyes-Closed vs Eyes-Open)\n",
    "3. MEG alpha oscillations (auditory vs visual stimulation)\n",
    "4. MEG alpha oscillations (faces vs scrambled) \n",
    "\n",
    "In these tasks, we will observe the effect of data imbalance on 4 different performance metrics :   \n",
    "1. Decoding Accuracy (Acc)  \n",
    "2. Area Under the Curve (AUC)\n",
    "3. F1\n",
    "4. Balanced Accuracy (BAcc)\n",
    "\n",
    "Finally, a few parameters of the classification pipeline must be kept in mind as they can also differentially impact performance on imbalanced data. Namely :\n",
    "- Dataset size\n",
    "- Classifier type\n",
    "    - Support Vector Machine (SVM)\n",
    "    - Linear Discriminant Analysis (LDA)\n",
    "    - Logistic Regression (LR)\n",
    "    - Random Forest (RF)\n",
    "- Cross-validation scheme\n",
    "    - K-Fold, k=5\n",
    "    - Stratified K-Fold\n",
    "    - Group K-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6890f8a3",
   "metadata": {},
   "source": [
    "## Imports\n",
    "First, we start by importing functions from the provided toolbox as well as some useful plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70295ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from imbalance.pipeline import Pipeline\n",
    "from imbalance.viz import metric_balance, data_distribution, plot_different_cvs, plot_different_n\n",
    "from imbalance.data import eegbci, gaussian_binary\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    StratifiedGroupKFold,\n",
    ")\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import string\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "plt.style.use('seaborn-dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df7c6a",
   "metadata": {},
   "source": [
    "## Task 1 : Synthetic data\n",
    "For that first classification task, we will generate data from two gaussian distributions, with means of 0 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bf96e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pls = []\n",
    "\n",
    "def run(distance):\n",
    "    # generate random data\n",
    "    x, y, groups = gaussian_binary(n_samples_per_class=500, mean_distance=distance)\n",
    "    # run the pipeline\n",
    "    pl = Pipeline(\n",
    "        x,\n",
    "        y,\n",
    "        groups,\n",
    "        dataset_balance=np.linspace(0.1, 0.9, 25),\n",
    "        classifiers=[\"lr\", \"lda\", \"svm\", \"rf\"],\n",
    "        n_permutations=100,\n",
    "        n_init=40,\n",
    "    )\n",
    "    pl.evaluate()\n",
    "    return deepcopy(pl)\n",
    "\n",
    "\n",
    "\n",
    "pls = Parallel(n_jobs=-1)(delayed(run)(dist) for dist in [0, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21060349",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_path = \"../imbalance/data/synthetic_pipelines.pickle\"\n",
    "with open(pls_path, \"wb\") as f:\n",
    "    pickle.dump(pls, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random data\n",
    "x, y, groups = gaussian_binary(n_samples_per_class=1500, mean_distance=1)\n",
    "# run the pipeline\n",
    "pl_nsamples = Pipeline(\n",
    "    x,\n",
    "    y,\n",
    "    groups,\n",
    "    dataset_balance=np.linspace(0.1, 0.9, 25),\n",
    "    classifiers=[\"svm\"],# \"rf\"]\n",
    "    n_permutations=0,\n",
    "    n_init=40,\n",
    "    dataset_size=(0.1, 0.33, 1),\n",
    ")\n",
    "pl_nsamples.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24768add",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_path = \"../imbalance/data/synthetic_pipelines_nsamples.pickle\"\n",
    "with open(pl_path, \"wb\") as f:\n",
    "    pickle.dump(pl_nsamples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f00fcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_inits = 40\n",
    "pls_crossvals = {}\n",
    "cv_names = [\"KFold\", \"Stratified\"]#, \"Stratified Group\"]\n",
    "cvs = [KFold(n_splits=5), StratifiedKFold(n_splits=5)]#, StratifiedGroupKFold(n_splits=5)]\n",
    "\n",
    "scores = {}\n",
    "for idx_init in range(n_inits):\n",
    "    # generate random data\n",
    "    # /!\\ N=100 in this analysis\n",
    "    x, y, groups = gaussian_binary(n_samples_per_class=50, mean_distance=1, rand_seed=idx_init)\n",
    "    \n",
    "    # run the pipeline\n",
    "    for idx_cv, cross_val in enumerate(cvs):\n",
    "        pl = Pipeline(\n",
    "            x,\n",
    "            y,\n",
    "            groups,\n",
    "            dataset_balance=np.linspace(0.1, 0.9, 25),\n",
    "            classifiers=[\"svm\"],\n",
    "            n_permutations=1,\n",
    "            n_init=1,\n",
    "            cross_validation=cross_val,\n",
    "            rand_seed=idx_init,\n",
    "        )\n",
    "        pl.evaluate()\n",
    "        pl = deepcopy(pl)\n",
    "        \n",
    "        pls_crossvals[cv_names[idx_cv]] = pl\n",
    "        \n",
    "        if cv_names[idx_cv] not in scores:\n",
    "            scores[cv_names[idx_cv]] = pl.scores\n",
    "        else:\n",
    "            for ratio in pl.scores.keys():\n",
    "                for size in pl.scores[ratio].keys():\n",
    "                    for clf in pl.scores[ratio][size].keys():\n",
    "                        for metric in pl.scores[ratio][size][clf].keys():\n",
    "                            if isinstance(scores[cv_names[idx_cv]][ratio][size][clf][metric], tuple):\n",
    "                                # use only the mean\n",
    "                                scores[cv_names[idx_cv]][ratio][size][clf][metric] = [scores[cv_names[idx_cv]][ratio][size][clf][metric][0]]\n",
    "                            \n",
    "                            # add current pipeline's score to the list\n",
    "                            scores[cv_names[idx_cv]][ratio][size][clf][metric].append(\n",
    "                                pl.scores[ratio][size][clf][metric][0]\n",
    "                            )\n",
    "\n",
    "# compute mean and std score\n",
    "for cv_name in cv_names:\n",
    "    curr_scores = scores[cv_name]\n",
    "    for ratio in curr_scores.keys():\n",
    "        for size in curr_scores[ratio].keys():\n",
    "            for clf in curr_scores[ratio][size].keys():\n",
    "                for metric in curr_scores[ratio][size][clf].keys():\n",
    "                    curr_scores[ratio][size][clf][metric] = (np.mean(curr_scores[ratio][size][clf][metric]),\n",
    "                                                             np.std(curr_scores[ratio][size][clf][metric]),\n",
    "                                                             None,\n",
    "                                                             None)\n",
    "    pls_crossvals[cv_name].scores = curr_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_path = \"../imbalance/data/synthetic_pipelines_crossvals.pickle\"\n",
    "with open(pl_path, \"wb\") as f:\n",
    "    pickle.dump(pls_crossvals, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328bb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random data\n",
    "x, y, groups = gaussian_binary(n_samples_per_class=500, mean_distance=1)\n",
    "# run the pipeline\n",
    "pl_balance = Pipeline(\n",
    "    x,\n",
    "    y,\n",
    "    groups,\n",
    "    dataset_balance=np.linspace(0.1, 0.9, 25),\n",
    "    classifiers=[\"svm\"],\n",
    "    n_permutations=0,\n",
    "    n_init=40,\n",
    "    single_balanced_split=True,\n",
    ")\n",
    "pl_balance.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca731165",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_path = \"../imbalance/data/synthetic_pipelines_balance.pickle\"\n",
    "with open(pl_path, \"wb\") as f:\n",
    "    pickle.dump(pl_balance, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca9e86e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(\"../imbalance/data/synthetic_pipelines.pickle\", \"rb\") as f:\n",
    "    pls = pickle.load(f)\n",
    "\n",
    "# visualize the result\n",
    "fig, axes = plt.subplots(5, 4, figsize=(15, 22), dpi=300, \n",
    "                         gridspec_kw=dict(height_ratios=[1, 1, 1, 1, 1], width_ratios=[0.1,1,1,1],\n",
    "                                          hspace=0.3))\n",
    "for ax in axes[:,0]:                              \n",
    "    ax.axis(\"off\")\n",
    "\n",
    "figtitle = \"Synthetic data\"\n",
    "fig.suptitle(figtitle, fontsize=20, y=0.92, fontweight=\"bold\")\n",
    "classifiers=[\"lr\", \"lda\", \"svm\", \"rf\"]\n",
    "spot_names = string.ascii_lowercase[:5*4]\n",
    "\n",
    "show_leg_distrib=True\n",
    "show_leg_metric=False\n",
    "spot_idx = 0\n",
    "for dist_idx, dist in enumerate([0,1,3]):\n",
    "    for ax_idx, ax in enumerate(axes[:,dist_idx+1]):\n",
    "        if dist_idx == 2 and ax_idx == 0:\n",
    "            show_leg_metric = True\n",
    "        \n",
    "        if ax_idx == 0:\n",
    "            data_distribution(pls[dist_idx], ax=ax, show=False, show_leg=show_leg_distrib)\n",
    "            show_leg_distrib=False\n",
    "        elif ax_idx < 5:\n",
    "            metric_balance(pls[dist_idx], ax=ax, p_threshold=0, show=False, \n",
    "                           classifier=classifiers[ax_idx-1], \n",
    "                           show_leg=show_leg_metric, show_title=False)\n",
    "            show_leg_metric = False\n",
    "        \n",
    "        ax.text(-0.12, 1.12, spot_names[spot_idx]+\")\", transform=ax.transAxes, \n",
    "                size=22, weight='bold')\n",
    "        spot_idx += 1\n",
    "\n",
    "cols = ['Distance = 0', 'Distance = 1', 'Distance = 3']\n",
    "rows = [\"Distributions\", \"LogisticRegression\", \"LinearDiscriminantAnalysis\", \"SupportVectorMachine\", \"RandomForest\"]\n",
    "\n",
    "for ax, col in zip(axes[0,1:], cols):\n",
    "    ax.set_title(col, size=20)\n",
    "\n",
    "for idx_ax, (ax, row) in enumerate(zip(axes[:,0], rows)):\n",
    "    ax.text(0.8,0.5,rows[idx_ax], fontsize=20, ha=\"right\", va=\"center\", rotation=90)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"Figure2.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e243d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../imbalance/data/synthetic_pipelines_nsamples.pickle\", \"rb\") as f:\n",
    "    pl_nsamples = pickle.load(f)\n",
    "with open(\"../imbalance/data/synthetic_pipelines_crossvals.pickle\", \"rb\") as f:\n",
    "    pls_crossvals = pickle.load(f)\n",
    "with open(\"../imbalance/data/synthetic_pipelines_balance.pickle\", \"rb\") as f:\n",
    "    pl_balance = pickle.load(f)\n",
    "with open(\"../imbalance/data/hparams_pipelines.pickle\", \"rb\") as f:\n",
    "    pls_hparams = pickle.load(f)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(22, 13), dpi=300, gridspec_kw=dict(hspace=0.2))\n",
    "figtitle = \"Synthetic data : secondary parameters\"\n",
    "fig.suptitle(figtitle, fontsize=28, y=0.96, fontweight=\"bold\")\n",
    "\n",
    "# hyperparameters (first row)\n",
    "for clf_idx, clf_name in enumerate(pls_hparams.keys()):\n",
    "    lines = []\n",
    "    for i_pl, curr_pl in enumerate(pls_hparams[clf_name].values()):\n",
    "        lines.extend(metric_balance(curr_pl, classifier=clf_name, color_offset=i_pl, ax=axes[0, clf_idx], \n",
    "                                    ignore_metrics=[\"roc_auc\", \"f1\", \"accuracy\"],\n",
    "                                    show=False, show_leg=True, enforce_ylim=False, reset_colors=True))\n",
    "    axes[0, clf_idx].legend(lines, pls_hparams[clf_name].keys(), prop={'size': 14})\n",
    "    axes[0, clf_idx].set_ylabel(\"Balanced Accuracy\", size=16)\n",
    "    \n",
    "# other analysis (second row)\n",
    "plot_different_n(pl_nsamples, ax=axes[1,0], show=False, classifier=\"svm\", show_leg=True, metric=\"accuracy\",\n",
    "                 legend_labels=[\"N=300\", \"N=1000\", \"N=3000\"])\n",
    "axes[1,0].set_title('Accuracy vs sample size (SVM)', size=18)\n",
    "\n",
    "plot_different_cvs(pls_crossvals, ax=axes[1,1], show=False, classifier=\"svm\", show_leg=True,\n",
    "                   metric=\"balanced_accuracy\")\n",
    "axes[1,1].set_title('Balanced Accuracy vs cross-validation (SVM)', size=18)\n",
    "\n",
    "metric_balance(pl_balance, ax=axes[1,2], show=False, classifier=\"svm\", show_leg=True, chance_leg=False,\n",
    "               ignore_metrics=['balanced_accuracy'])\n",
    "axes[1,2].set_title('Balanced Hold-out set (SVM)', size=18)\n",
    "\n",
    "spot_names = string.ascii_lowercase[:5*4]\n",
    "for ax_idx, ax in enumerate(axes.flat):\n",
    "    ax.text(-0.1, 1.07, spot_names[ax_idx]+\")\", transform=ax.transAxes, \n",
    "            size=26, weight='bold')\n",
    "\n",
    "plt.subplots_adjust()\n",
    "plt.savefig(\"Figure3.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc0d0b",
   "metadata": {},
   "source": [
    "## Task 2 : EEG analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f01e040",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pipeline_path=\"../imbalance/data/eeg.pickle\"\n",
    "features_path =\"../imbalance/data/eeg_features.npy\"\n",
    "\n",
    "# load or generate dataset\n",
    "if not os.path.isfile(features_path):\n",
    "    x, y, groups = eegbci('../imbalance/data',roi=lambda x: x[0] in ['P','O'])\n",
    "    np.save(features_path,dict(x=x, y=y, groups=groups))\n",
    "else:\n",
    "    features = np.load(features_path,allow_pickle=True).item()\n",
    "    x, y, groups = features[\"x\"] , features[\"y\"] , features[\"groups\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcfb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(\n",
    "    x,\n",
    "    y,\n",
    "    groups,\n",
    "    dataset_balance=np.linspace(0.1, 0.9, 25),\n",
    "    classifiers=[\"lda\",\"svm\",\"lr\", \"rf\"]\n",
    ")\n",
    "# fit and evaluate classifiers on dataset configurations\n",
    "pl.evaluate()\n",
    "\n",
    "pl_nsamples = Pipeline(\n",
    "    x,\n",
    "    y,\n",
    "    groups,\n",
    "    dataset_balance=np.linspace(0.1, 0.9, 25),\n",
    "    classifiers=[\"svm\"],# \"rf\"]\n",
    "    n_permutations=0,\n",
    "    n_init=10,\n",
    "    dataset_size=(0.1, 0.33, 1),\n",
    ")\n",
    "pl_nsamples.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b37e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fpath = \"../imbalance/data/eeg_roi_multi_Stratified-Group.pickle\"\n",
    "with open(fpath, \"rb\") as f:\n",
    "    pl = pickle.load(f)\n",
    "\n",
    "def task_panel(pl: Pipeline, figtitle: str=[], class_names=[]):\n",
    "    # visualize the result\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 14))\n",
    "    #fig.suptitle(figtitle, fontsize=25)\n",
    "    classifiers=[\"lr\", \"lda\", \"svm\", \"rf\"]\n",
    "    show_leg_metric=True\n",
    "    for ax_idx,ax in enumerate(axes.flat):\n",
    "        if ax_idx != 5:\n",
    "            ax.text(-0.1, 1.05, string.ascii_lowercase[ax_idx]+\")\", transform=ax.transAxes, \n",
    "                    size=22, weight='bold')\n",
    "        if ax_idx == 0:\n",
    "            data_distribution(pl, ax=ax, show=False, class_names=class_names)\n",
    "        elif ax_idx < 5:\n",
    "            metric_balance(pl, ax=ax, show=False, classifier=classifiers[ax_idx-1], p_threshold=0, show_leg=show_leg_metric)\n",
    "            show_leg_metric=False\n",
    "        elif ax_idx == 5:\n",
    "            ax.axis('off')\n",
    "            #plot_different_n(pl_nsamples, ax=ax, show=False, classifier=\"svm\", show_leg=True, metric=\"accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "figtitle = \"EEG data multi\"\n",
    "task_panel(pl, figtitle, ['Eyes closed', 'Eyes open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d07702",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from imbalance.data.eeg import get_info\n",
    "import mne\n",
    "\n",
    "fpath = \"../imbalance/data/eeg_roi_multi_Stratified-Group.pickle\"\n",
    "with open(fpath, \"rb\") as f:\n",
    "    pl = pickle.load(f)\n",
    "#tval = np.load(\"../imbalance/data/gamma1_tvalues.npy\")    \n",
    "\n",
    "figtitle = \"EEG : Eyes Closed VS Open\"\n",
    "class_names = ['Eyes Closed', 'Eyes Open']\n",
    "# visualize the result\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle(figtitle, fontsize=28, y=0.97, fontweight=\"bold\")\n",
    "classifiers=[\"lr\", \"lda\", \"svm\", \"rf\"]\n",
    "\n",
    "data_distribution(pl, ax=axes[0,0], show=False, class_names=class_names)\n",
    "#axes[0,0].set_xlim(-2.5,5)\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "info = get_info()\n",
    "roi = [x for x in info['ch_names'] if x[0] in ['P','O']]\n",
    "sphere=(0, 0.015, 0.01, 0.115)\n",
    "\n",
    "metric_balance(pl, ax=axes[0,1], show=False, classifier=\"lr\", p_threshold=0, show_leg=True)\n",
    "metric_balance(pl, ax=axes[0,2], show=False, classifier=\"lda\", p_threshold=0, show_leg=False)\n",
    "metric_balance(pl, ax=axes[1,1], show=False, classifier=\"svm\", p_threshold=0, show_leg=False)\n",
    "metric_balance(pl, ax=axes[1,2], show=False, classifier=\"rf\", p_threshold=0, show_leg=False)\n",
    "\n",
    "for ax_idx,ax in enumerate(axes.T.flat):\n",
    "    ax.text(-0.1, 1.075, string.ascii_lowercase[ax_idx]+\")\", transform=ax.transAxes, \n",
    "            size=26, weight='bold')\n",
    "\n",
    "# plot topomap and highlight selected sensors\n",
    "crange = np.linspace(1, 0, 100)\n",
    "cm = ListedColormap(np.stack((np.ones(len(crange)), crange, crange, np.ones(len(crange))), axis=1))\n",
    "mask = np.array(list(map(lambda x: x.startswith((\"O\", \"P\")), info.ch_names)))\n",
    "vals = np.zeros(len(info.ch_names))\n",
    "vals[mask] = 1\n",
    "with sns.axes_style(\"white\"):\n",
    "    mne.viz.plot_sensors(info, axes=axes[1,0], show=False, sphere=sphere)\n",
    "    #mne.viz.plot_topomap(vals, info, axes=axes[1,0], image_interp=\"sinc\", res=62, show=False,\n",
    "    #                     sphere=(0, 0.018, 0.01, 0.1), show_names=False, contours=False, extrapolate=\"local\",\n",
    "    #                     vmin=0, vmax=4, cmap=cm, mask=np.ones(vals.shape),\n",
    "    #                     mask_params=dict(marker=\"o\", markersize=6, markerfacecolor=\"0\"))\n",
    "    \n",
    "plt.savefig(\"Figure4.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad8490",
   "metadata": {},
   "source": [
    "## Task 3 : MEG 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd82c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import string\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne.viz import plot_topomap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def load_info():\n",
    "    data_path = mne.datasets.sample.data_path()\n",
    "    raw = mne.io.read_raw_fif(\n",
    "        f\"{data_path}/MEG/sample/sample_audvis_raw.fif\", preload=False\n",
    "    )\n",
    "    return raw.pick_types(meg=\"mag\").info\n",
    "\n",
    "def generate_topomap(\n",
    "    data,\n",
    "    elec=None,\n",
    "    ax= None,\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "    res=128,\n",
    "    cmap=\"viridis\",\n",
    "    colorbar=True,\n",
    "    tight_layout=True,\n",
    "    mask=None,\n",
    "    mask_params=None,\n",
    "):    \n",
    "    if elec is not None:\n",
    "        mask_params = dict(marker='o', markerfacecolor='w', markeredgecolor='k', linewidth=0, markersize=20)\n",
    "        mask = np.zeros(102).astype(bool)\n",
    "        mask[elec] = True\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    im, _ = plot_topomap(\n",
    "        data,\n",
    "        load_info(),\n",
    "        axes=ax,\n",
    "        res=128,\n",
    "        cmap=cmap,\n",
    "        vmax=data.max() if vmax is None else vmax,\n",
    "        vmin=data.min() if vmin is None else vmin,\n",
    "        show=False,\n",
    "        show_names=False,\n",
    "        contours=False,\n",
    "        sensors=False,\n",
    "        extrapolate=\"local\",\n",
    "        mask=mask,\n",
    "        mask_params=mask_params,\n",
    "    )\n",
    "    \n",
    "    divider = make_axes_locatable(ax)\n",
    "    ax_colorbar = divider.append_axes('bottom', size='5%', pad=0.05)\n",
    "    plt.colorbar(im, cax=ax_colorbar, orientation='horizontal')\n",
    "    ax_colorbar.set_xlabel('t-values', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049fb76e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"axes.edgecolor\": \"black\"})\n",
    "\n",
    "fpath = \"../imbalance/data/MEG_gamma1_imbalance_78.pckl\"\n",
    "with open(fpath, \"rb\") as f:\n",
    "    pl = pickle.load(f)\n",
    "tval = np.load(\"../imbalance/data/gamma1_tvalues.npy\")    \n",
    "\n",
    "figtitle = \"MEG Cam-CAN : Visual VS Auditory stimulation\"\n",
    "class_names = ['Visual', 'Auditory']\n",
    "# visualize the result\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle(figtitle, fontsize=28, y=1.02, fontweight=\"bold\")\n",
    "classifiers=[\"lr\", \"lda\", \"svm\", \"rf\"]\n",
    "\n",
    "data_distribution(pl, ax=axes[0,0], show=False, class_names=class_names)\n",
    "axes[0,0].set_xlim(-2.5,5)\n",
    "\n",
    "generate_topomap(tval, ax=axes[1,0], elec=78)\n",
    "axes[1,0].set_xlabel('T-values', fontsize=16)\n",
    "\n",
    "metric_balance(pl, ax=axes[0,1], show=False, classifier=\"lr\", p_threshold=0, show_leg=True)\n",
    "metric_balance(pl, ax=axes[0,2], show=False, classifier=\"lda\", p_threshold=0, show_leg=False)\n",
    "metric_balance(pl, ax=axes[1,1], show=False, classifier=\"svm\", p_threshold=0, show_leg=False)\n",
    "metric_balance(pl, ax=axes[1,2], show=False, classifier=\"rf\", p_threshold=0, show_leg=False)\n",
    "\n",
    "for ax_idx,ax in enumerate(axes.T.flat):\n",
    "    ax.text(-0.1, 1.05, string.ascii_lowercase[ax_idx]+\")\", transform=ax.transAxes, \n",
    "        size=24, weight='bold')\n",
    "plt.savefig(\"Figure6.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.rcParams.update({\"axes.edgecolor\": \"white\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a07e9",
   "metadata": {},
   "source": [
    "## Task 4 : MEG 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d65e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fpath = \"../imbalance/data/MEG_gamma1_imbalance_78.pckl\"\n",
    "with open(fpath, \"rb\") as f:\n",
    "    pl = pickle.load(f)\n",
    "tval = np.load(\"../imbalance/data/gamma1_tvalues.npy\")    \n",
    "\n",
    "figtitle = \"MEG Cam-CAN : Visual VS Auditory stimulation\"\n",
    "class_names = ['Visual', 'Auditory']\n",
    "# visualize the result\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 14))\n",
    "fig.suptitle(figtitle, fontsize=28, y=1.02, fontweight=\"bold\")\n",
    "classifiers=[\"lr\", \"lda\", \"svm\", \"rf\"]\n",
    "\n",
    "data_distribution(pl, ax=[0,0], show=False, class_names=class_names)\n",
    "axes[0,0].set_xlim(-2.5,5)\n",
    "\n",
    "generate_topomap(tval, ax=ax[1,0], elec=78)\n",
    "\n",
    "metric_balance(pl, ax=ax[0,1], show=False, classifier=\"lr\", p_threshold=0, show_leg=True)\n",
    "metric_balance(pl, ax=ax[0,2], show=False, classifier=\"lda\", p_threshold=0, show_leg=False)\n",
    "metric_balance(pl, ax=ax[1,1], show=False, classifier=\"svm\", p_threshold=0, show_leg=False)\n",
    "metric_balance(pl, ax=ax[1,2], show=False, classifier=\"rf\", p_threshold=0, show_leg=False)\n",
    "\n",
    "show_leg_metric=True\n",
    "for ax_idx,ax in enumerate(axes.flat):\n",
    "    if ax_idx != 5:\n",
    "        ax.text(-0.1, 1.05, string.ascii_lowercase[ax_idx]+\")\", transform=ax.transAxes, \n",
    "                size=20, weight='bold')\n",
    "    if ax_idx == 0:\n",
    "        data_distribution(pl, ax=ax, show=False, class_names=class_names)\n",
    "        ax.set_xlim(-2.5,5)\n",
    "    elif ax_idx < 5:\n",
    "        metric_balance(pl, ax=ax, show=False, classifier=classifiers[ax_idx-1], p_threshold=0, show_leg=show_leg_metric)\n",
    "        show_leg_metric=False\n",
    "    elif ax_idx == 5:\n",
    "        generate_topomap(tval, ax=ax, elec=78)\n",
    "        #ax.axis('off')\n",
    "        #plot_different_n(pl_nsamples, ax=ax, show=False, classifier=\"svm\", show_leg=True, metric=\"accuracy\")\n",
    "plt.show()\n",
    "\n",
    "#task_panel(pl, figtitle, '])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df2d858",
   "metadata": {},
   "source": [
    "# Significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154875f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_pipeline_significance(dist):\n",
    "    # generate random data\n",
    "    x, y, groups = gaussian_binary(n_samples_per_class=500, mean_distance=dist)\n",
    "    # run the pipeline\n",
    "    pl = Pipeline(\n",
    "        x,\n",
    "        y,\n",
    "        groups,\n",
    "        dataset_balance=np.linspace(0.1, 0.9, 25),\n",
    "        classifiers=\"svm\",\n",
    "        n_permutations=100,\n",
    "        n_init=1,\n",
    "    )\n",
    "    pl.evaluate()\n",
    "    return dist, pl\n",
    "\n",
    "results = Parallel(n_jobs=-1)(delayed(run_pipeline_significance)(dist) for dist in [0, 1, 3])\n",
    "results = dict(results)\n",
    "\n",
    "pl_path = \"../imbalance/data/synthetic_pipelines_significance.pickle\"\n",
    "with open(pl_path, \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295064ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"../imbalance/data/synthetic_pipelines_significance.pickle\", \"rb\") as f:\n",
    "    pl_significance = pickle.load(f)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=len(pl_significance), figsize=(18, 5))\n",
    "for i, (dist, pl) in enumerate(pl_significance.items()):\n",
    "    show_leg = dist == list(pl_significance.keys())[-1]\n",
    "    metric_balance(pl, classifier=\"svm\", ax=axes[i], show=False, show_leg=show_leg)\n",
    "    axes[i].set_title(f\"Distance = {dist} (SVM)\", fontsize=20)\n",
    "    \n",
    "for ax_idx, ax in enumerate(axes):\n",
    "    ax.text(-0.1, 1.09, string.ascii_lowercase[ax_idx]+\")\", transform=ax.transAxes, \n",
    "            size=22, weight='bold')\n",
    "\n",
    "plt.savefig(\"Figure7_supp.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa36f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
